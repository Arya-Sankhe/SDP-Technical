{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment: MSFT 1-Minute GRU Recursive Forecast (PRD)\n",
        "\n",
        "Objective:\n",
        "- Train a PyTorch GRU on MSFT 1-minute OHLC candles (target: last 60 days).\n",
        "- Use 500-candle windows to predict the next candle.\n",
        "- Recursively forecast 15 future candles from one seed window.\n",
        "- Visualize predicted candles in a black-and-white candlestick style.\n",
        "\n",
        "Success criteria:\n",
        "- Notebook runs top-to-bottom and reports one-step and recursive metrics.\n",
        "- Final chart clearly distinguishes historical, actual future, and predicted future candles in grayscale.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional dependency bootstrap (kept lightweight).\n",
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "required = {\n",
        "    'yfinance': 'yfinance',\n",
        "    'numpy': 'numpy',\n",
        "    'pandas': 'pandas',\n",
        "    'matplotlib': 'matplotlib',\n",
        "    'sklearn': 'scikit-learn',\n",
        "}\n",
        "\n",
        "missing = [pkg for module_name, pkg in required.items() if importlib.util.find_spec(module_name) is None]\n",
        "if missing:\n",
        "    print('Installing missing packages:', missing)\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', *missing])\n",
        "else:\n",
        "    print('All required third-party packages are already installed.')\n",
        "\n",
        "print('If torch is missing, install it separately with a CUDA wheel suitable for your RTX 3070 and driver.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup: imports and reproducibility\n",
        "from __future__ import annotations\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import yfinance as yf\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import display\n",
        "from matplotlib.patches import Patch, Rectangle\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(f'Using device: {DEVICE}')\n",
        "if torch.cuda.is_available():\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "    print('CUDA:', torch.version.cuda)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plan\n",
        "\n",
        "- Data: download MSFT 1-minute OHLC candles over 60 days using chunked Yahoo requests.\n",
        "- Features: raw OHLC only (no indicators).\n",
        "- Model: 2-layer GRU (hidden=128, dropout=0.2) -> linear head to next OHLC.\n",
        "- Training: time-aware split, train-only normalization, MSE loss, Adam, early stopping.\n",
        "- Inference: recursive 15-step forecast using own predictions as future inputs.\n",
        "- Visualization: grayscale candlestick plot with predicted candles emphasized in white.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Experiment configuration\n",
        "SYMBOL = 'MSFT'\n",
        "INTERVAL = '1m'\n",
        "LOOKBACK_DAYS = 60\n",
        "CHUNK_DAYS = 6\n",
        "FEATURES = ['Open', 'High', 'Low', 'Close']\n",
        "\n",
        "WINDOW = 500\n",
        "HORIZON = 15\n",
        "\n",
        "TRAIN_RATIO = 0.70\n",
        "VAL_RATIO = 0.15\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "HIDDEN_SIZE = 128\n",
        "NUM_LAYERS = 2\n",
        "DROPOUT = 0.2\n",
        "LEARNING_RATE = 1e-3\n",
        "EPOCHS = 12\n",
        "PATIENCE = 3\n",
        "\n",
        "print({\n",
        "    'symbol': SYMBOL,\n",
        "    'interval': INTERVAL,\n",
        "    'lookback_days': LOOKBACK_DAYS,\n",
        "    'window': WINDOW,\n",
        "    'horizon': HORIZON,\n",
        "    'device': str(DEVICE),\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data download and cleaning\n",
        "def fetch_ohlc_1m(symbol: str, lookback_days: int, chunk_days: int = 6, pause_seconds: float = 0.25) -> pd.DataFrame:\n",
        "    end_ts = pd.Timestamp.utcnow().floor('min')\n",
        "    start_ts = end_ts - pd.Timedelta(days=lookback_days)\n",
        "\n",
        "    frames: list[pd.DataFrame] = []\n",
        "    cursor = start_ts\n",
        "\n",
        "    while cursor < end_ts:\n",
        "        chunk_end = min(cursor + pd.Timedelta(days=chunk_days), end_ts)\n",
        "        chunk = yf.download(\n",
        "            tickers=symbol,\n",
        "            start=cursor.to_pydatetime(),\n",
        "            end=chunk_end.to_pydatetime(),\n",
        "            interval='1m',\n",
        "            auto_adjust=False,\n",
        "            prepost=False,\n",
        "            progress=False,\n",
        "            threads=False,\n",
        "        )\n",
        "\n",
        "        if not chunk.empty:\n",
        "            if isinstance(chunk.columns, pd.MultiIndex):\n",
        "                chunk.columns = chunk.columns.get_level_values(0)\n",
        "\n",
        "            missing_cols = [c for c in FEATURES if c not in chunk.columns]\n",
        "            if missing_cols:\n",
        "                raise ValueError(f'Missing OHLC columns: {missing_cols}')\n",
        "\n",
        "            chunk = chunk[FEATURES].copy()\n",
        "            frames.append(chunk)\n",
        "\n",
        "        cursor = chunk_end\n",
        "        time.sleep(pause_seconds)\n",
        "\n",
        "    if not frames:\n",
        "        raise RuntimeError('No 1-minute candles were returned. Try again during market hours or use another data source.')\n",
        "\n",
        "    df = pd.concat(frames, axis=0).sort_index()\n",
        "    df = df[~df.index.duplicated(keep='last')]\n",
        "    df = df.dropna(subset=FEATURES)\n",
        "\n",
        "    idx = pd.DatetimeIndex(df.index)\n",
        "    if idx.tz is not None:\n",
        "        idx = idx.tz_convert('UTC').tz_localize(None)\n",
        "    df.index = idx\n",
        "\n",
        "    return df\n",
        "\n",
        "raw_df = fetch_ohlc_1m(SYMBOL, LOOKBACK_DAYS, CHUNK_DAYS)\n",
        "raw_df = raw_df.astype(np.float32)\n",
        "\n",
        "span_days = (raw_df.index.max() - raw_df.index.min()).total_seconds() / 86400\n",
        "print(f'Rows: {len(raw_df):,}')\n",
        "print(f'Time span in returned data: {span_days:.1f} days')\n",
        "if span_days < LOOKBACK_DAYS * 0.9:\n",
        "    print('Warning: Data vendor returned less than 60 days of 1-minute bars. This is a provider limitation, not a modeling change.')\n",
        "\n",
        "min_needed = WINDOW + HORIZON + 200\n",
        "if len(raw_df) < min_needed:\n",
        "    raise RuntimeError(f'Not enough rows ({len(raw_df)}) for window={WINDOW} and horizon={HORIZON}. Need at least {min_needed}.')\n",
        "\n",
        "raw_df.tail()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build sequences with train/val/test time split and train-only normalization\n",
        "def split_indices(n_rows: int, train_ratio: float, val_ratio: float) -> tuple[int, int]:\n",
        "    train_end = int(n_rows * train_ratio)\n",
        "    val_end = int(n_rows * (train_ratio + val_ratio))\n",
        "    return train_end, val_end\n",
        "\n",
        "\n",
        "def make_windows(values: np.ndarray, window: int) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    X, y, target_idx = [], [], []\n",
        "    for i in range(window, len(values)):\n",
        "        X.append(values[i - window : i])\n",
        "        y.append(values[i])\n",
        "        target_idx.append(i)\n",
        "\n",
        "    return (\n",
        "        np.asarray(X, dtype=np.float32),\n",
        "        np.asarray(y, dtype=np.float32),\n",
        "        np.asarray(target_idx, dtype=np.int64),\n",
        "    )\n",
        "\n",
        "\n",
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
        "        self.X = torch.from_numpy(X).float()\n",
        "        self.y = torch.from_numpy(y).float()\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "\n",
        "raw_values = raw_df[FEATURES].to_numpy(dtype=np.float32)\n",
        "train_end, val_end = split_indices(len(raw_df), TRAIN_RATIO, VAL_RATIO)\n",
        "\n",
        "train_mean = raw_values[:train_end].mean(axis=0)\n",
        "train_std = raw_values[:train_end].std(axis=0)\n",
        "train_std = np.where(train_std < 1e-8, 1.0, train_std)\n",
        "\n",
        "scaled_values = (raw_values - train_mean) / train_std\n",
        "\n",
        "X_all, y_all, seq_idx = make_windows(scaled_values, WINDOW)\n",
        "\n",
        "train_mask = seq_idx < train_end\n",
        "val_mask = (seq_idx >= train_end) & (seq_idx < val_end)\n",
        "test_mask = seq_idx >= val_end\n",
        "\n",
        "X_train, y_train = X_all[train_mask], y_all[train_mask]\n",
        "X_val, y_val = X_all[val_mask], y_all[val_mask]\n",
        "X_test, y_test = X_all[test_mask], y_all[test_mask]\n",
        "\n",
        "train_loader = DataLoader(SequenceDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "val_loader = DataLoader(SequenceDataset(X_val, y_val), batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "test_loader = DataLoader(SequenceDataset(X_test, y_test), batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
        "\n",
        "print('Split rows:', {'train': train_end, 'val': val_end - train_end, 'test': len(raw_df) - val_end})\n",
        "print('Windowed samples:', {'train': len(X_train), 'val': len(X_val), 'test': len(X_test)})\n",
        "print('X_train shape:', X_train.shape, 'y_train shape:', y_train.shape)\n",
        "if len(X_train) == 0 or len(X_val) == 0 or len(X_test) == 0:\n",
        "    raise RuntimeError('One or more splits are empty. Increase data range or adjust split ratios.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GRU model + training loop\n",
        "class GRUForecaster(nn.Module):\n",
        "    def __init__(self, input_size: int = 4, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.2):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0,\n",
        "        )\n",
        "        self.head = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        out, _ = self.gru(x)\n",
        "        return self.head(out[:, -1, :])\n",
        "\n",
        "\n",
        "def run_epoch(model: nn.Module, loader: DataLoader, loss_fn: nn.Module, optimizer: torch.optim.Optimizer | None = None) -> float:\n",
        "    is_train = optimizer is not None\n",
        "    model.train(is_train)\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_items = 0\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "\n",
        "        if is_train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.set_grad_enabled(is_train):\n",
        "            pred = model(xb)\n",
        "            loss = loss_fn(pred, yb)\n",
        "\n",
        "        if is_train:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        batch_size = xb.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total_items += batch_size\n",
        "\n",
        "    return total_loss / max(total_items, 1)\n",
        "\n",
        "\n",
        "def train_model(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader, epochs: int, lr: float, patience: int):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    best_val = float('inf')\n",
        "    best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "    wait = 0\n",
        "    history = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = run_epoch(model, train_loader, loss_fn, optimizer)\n",
        "        val_loss = run_epoch(model, val_loader, loss_fn, optimizer=None)\n",
        "\n",
        "        history.append({'epoch': epoch, 'train_loss': train_loss, 'val_loss': val_loss})\n",
        "        print(f'Epoch {epoch:02d} | train_loss={train_loss:.6f} | val_loss={val_loss:.6f}')\n",
        "\n",
        "        if val_loss < best_val:\n",
        "            best_val = val_loss\n",
        "            best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "            wait = 0\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait >= patience:\n",
        "                print(f'Early stopping at epoch {epoch}.')\n",
        "                break\n",
        "\n",
        "    model.load_state_dict(best_state)\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train\n",
        "model = GRUForecaster(\n",
        "    input_size=len(FEATURES),\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    dropout=DROPOUT,\n",
        ").to(DEVICE)\n",
        "\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    epochs=EPOCHS,\n",
        "    lr=LEARNING_RATE,\n",
        "    patience=PATIENCE,\n",
        ")\n",
        "\n",
        "history_df = pd.DataFrame(history)\n",
        "display(history_df.tail())\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(history_df['epoch'], history_df['train_loss'], label='Train', color='black')\n",
        "plt.plot(history_df['epoch'], history_df['val_loss'], label='Validation', color='gray')\n",
        "plt.title('GRU Loss Curves')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# One-step evaluation on test set\n",
        "def inverse_scale(arr: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
        "    return arr * std + mean\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def collect_preds(model: nn.Module, loader: DataLoader) -> tuple[np.ndarray, np.ndarray]:\n",
        "    model.eval()\n",
        "    preds, targets = [], []\n",
        "\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yhat = model(xb).cpu().numpy()\n",
        "        preds.append(yhat)\n",
        "        targets.append(yb.numpy())\n",
        "\n",
        "    return np.vstack(preds), np.vstack(targets)\n",
        "\n",
        "\n",
        "pred_test_scaled, y_test_scaled = collect_preds(model, test_loader)\n",
        "pred_test = inverse_scale(pred_test_scaled, train_mean, train_std)\n",
        "y_test_raw = inverse_scale(y_test_scaled, train_mean, train_std)\n",
        "\n",
        "test_target_indices = seq_idx[test_mask]\n",
        "prev_close = raw_values[test_target_indices - 1, 3]\n",
        "actual_close = y_test_raw[:, 3]\n",
        "pred_close = pred_test[:, 3]\n",
        "\n",
        "close_mae = mean_absolute_error(actual_close, pred_close)\n",
        "close_rmse = mean_squared_error(actual_close, pred_close, squared=False)\n",
        "ohlc_mae = mean_absolute_error(y_test_raw.reshape(-1), pred_test.reshape(-1))\n",
        "ohlc_rmse = mean_squared_error(y_test_raw.reshape(-1), pred_test.reshape(-1), squared=False)\n",
        "dir_acc = np.mean(np.sign(actual_close - prev_close) == np.sign(pred_close - prev_close))\n",
        "\n",
        "one_step_metrics = {\n",
        "    'close_mae': float(close_mae),\n",
        "    'close_rmse': float(close_rmse),\n",
        "    'ohlc_mae': float(ohlc_mae),\n",
        "    'ohlc_rmse': float(ohlc_rmse),\n",
        "    'directional_accuracy': float(dir_acc),\n",
        "}\n",
        "\n",
        "print('One-step test metrics:')\n",
        "for k, v in one_step_metrics.items():\n",
        "    print(f'  {k}: {v:.6f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recursive 15-step forecast\n",
        "@torch.no_grad()\n",
        "def recursive_forecast(model: nn.Module, seed_window_scaled: np.ndarray, horizon: int) -> np.ndarray:\n",
        "    model.eval()\n",
        "    window = seed_window_scaled.copy()\n",
        "    preds = []\n",
        "\n",
        "    for _ in range(horizon):\n",
        "        x = torch.from_numpy(window).float().unsqueeze(0).to(DEVICE)\n",
        "        next_step = model(x).cpu().numpy()[0]\n",
        "        preds.append(next_step)\n",
        "        window = np.vstack([window[1:], next_step])\n",
        "\n",
        "    return np.asarray(preds, dtype=np.float32)\n",
        "\n",
        "\n",
        "anchor_end = len(raw_df) - HORIZON - 1\n",
        "if anchor_end - WINDOW + 1 < 0:\n",
        "    raise RuntimeError('Not enough rows for recursive seed window.')\n",
        "\n",
        "seed_scaled = scaled_values[anchor_end - WINDOW + 1 : anchor_end + 1]\n",
        "recursive_scaled = recursive_forecast(model, seed_scaled, HORIZON)\n",
        "recursive_pred = inverse_scale(recursive_scaled, train_mean, train_std)\n",
        "\n",
        "future_actual = raw_values[anchor_end + 1 : anchor_end + 1 + HORIZON]\n",
        "future_index = raw_df.index[anchor_end + 1 : anchor_end + 1 + HORIZON]\n",
        "\n",
        "pred_future_df = pd.DataFrame(recursive_pred, index=future_index, columns=FEATURES)\n",
        "actual_future_df = pd.DataFrame(future_actual, index=future_index, columns=FEATURES)\n",
        "\n",
        "recursive_close_mae = mean_absolute_error(actual_future_df['Close'], pred_future_df['Close'])\n",
        "recursive_close_rmse = mean_squared_error(actual_future_df['Close'], pred_future_df['Close'], squared=False)\n",
        "\n",
        "print('Recursive 15-step metrics (close):')\n",
        "print(f'  mae:  {recursive_close_mae:.6f}')\n",
        "print(f'  rmse: {recursive_close_rmse:.6f}')\n",
        "\n",
        "display(pd.concat({\n",
        "    'actual_close': actual_future_df['Close'],\n",
        "    'pred_close': pred_future_df['Close'],\n",
        "}, axis=1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Candlestick rendering with requested color mapping\n",
        "# - History: green (bullish) / red (bearish)\n",
        "# - Predicted: white (bullish) / black (bearish)\n",
        "def draw_candles(\n",
        "    ax,\n",
        "    ohlc: pd.DataFrame,\n",
        "    start_x: int,\n",
        "    up_edge: str,\n",
        "    up_face: str,\n",
        "    down_edge: str,\n",
        "    down_face: str,\n",
        "    wick_color: str,\n",
        "    width: float = 0.62,\n",
        "    lw: float = 1.0,\n",
        "    alpha: float = 1.0,\n",
        "):\n",
        "    values = ohlc[['Open', 'High', 'Low', 'Close']].to_numpy()\n",
        "\n",
        "    for i, (o, h, l, c) in enumerate(values):\n",
        "        x = start_x + i\n",
        "        bullish = c >= o\n",
        "\n",
        "        ax.vlines(x, l, h, color=wick_color, linewidth=lw, alpha=alpha, zorder=2)\n",
        "\n",
        "        lower = min(o, c)\n",
        "        height = abs(c - o)\n",
        "        if height < 1e-8:\n",
        "            height = 1e-6\n",
        "\n",
        "        face = up_face if bullish else down_face\n",
        "        edge = up_edge if bullish else down_edge\n",
        "\n",
        "        rect = Rectangle(\n",
        "            (x - width / 2, lower),\n",
        "            width,\n",
        "            height,\n",
        "            facecolor=face,\n",
        "            edgecolor=edge,\n",
        "            linewidth=lw,\n",
        "            alpha=alpha,\n",
        "            zorder=3,\n",
        "        )\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "\n",
        "context_bars = 170\n",
        "context_start = max(0, anchor_end - context_bars + 1)\n",
        "context_df = raw_df.iloc[context_start : anchor_end + 1][FEATURES].copy()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(17, 8), facecolor='black')\n",
        "ax.set_facecolor('black')\n",
        "\n",
        "# Historical candles (actual): green/red\n",
        "draw_candles(\n",
        "    ax,\n",
        "    context_df,\n",
        "    start_x=0,\n",
        "    up_edge='#2ECC71',\n",
        "    up_face='#2ECC71',\n",
        "    down_edge='#E74C3C',\n",
        "    down_face='#E74C3C',\n",
        "    wick_color='#D9D9D9',\n",
        "    width=0.58,\n",
        "    lw=1.0,\n",
        "    alpha=0.95,\n",
        ")\n",
        "\n",
        "# Actual future candles (for comparison): muted green/red\n",
        "draw_candles(\n",
        "    ax,\n",
        "    actual_future_df,\n",
        "    start_x=len(context_df),\n",
        "    up_edge='#1E8F4E',\n",
        "    up_face='#1E8F4E',\n",
        "    down_edge='#B03A2E',\n",
        "    down_face='#B03A2E',\n",
        "    wick_color='#9A9A9A',\n",
        "    width=0.58,\n",
        "    lw=1.0,\n",
        "    alpha=0.75,\n",
        ")\n",
        "\n",
        "# Predicted future candles: white if bullish (green-equivalent), black if bearish (red-equivalent)\n",
        "draw_candles(\n",
        "    ax,\n",
        "    pred_future_df,\n",
        "    start_x=len(context_df),\n",
        "    up_edge='#FFFFFF',\n",
        "    up_face='#FFFFFF',\n",
        "    down_edge='#000000',\n",
        "    down_face='#000000',\n",
        "    wick_color='#F0F0F0',\n",
        "    width=0.50,\n",
        "    lw=1.35,\n",
        "    alpha=1.0,\n",
        ")\n",
        "\n",
        "split_x = len(context_df) - 0.5\n",
        "ax.axvline(split_x, color='white', linestyle='--', linewidth=0.8, alpha=0.5)\n",
        "\n",
        "combined_index = context_df.index.append(actual_future_df.index)\n",
        "total_bars = len(combined_index)\n",
        "tick_step = max(1, total_bars // 10)\n",
        "ticks = list(range(0, total_bars, tick_step))\n",
        "if ticks[-1] != total_bars - 1:\n",
        "    ticks.append(total_bars - 1)\n",
        "\n",
        "labels = [combined_index[i].strftime('%m-%d %H:%M') for i in ticks]\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_xticklabels(labels, rotation=28, ha='right', color='white', fontsize=9)\n",
        "\n",
        "ax.tick_params(axis='y', colors='white')\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_color('#606060')\n",
        "\n",
        "ax.grid(color='#222222', linewidth=0.6, alpha=0.35)\n",
        "ax.set_title('MSFT 1-Minute Candles: History + 15-Step Recursive GRU Forecast', color='white', pad=16)\n",
        "ax.set_ylabel('Price', color='white')\n",
        "\n",
        "legend_elements = [\n",
        "    Patch(facecolor='#2ECC71', edgecolor='#2ECC71', label='History bullish (green)'),\n",
        "    Patch(facecolor='#E74C3C', edgecolor='#E74C3C', label='History bearish (red)'),\n",
        "    Patch(facecolor='#FFFFFF', edgecolor='#FFFFFF', label='Predicted bullish (white)'),\n",
        "    Patch(facecolor='#000000', edgecolor='#FFFFFF', label='Predicted bearish (black)'),\n",
        "]\n",
        "leg = ax.legend(handles=legend_elements, facecolor='black', edgecolor='#707070', framealpha=1.0, loc='upper left')\n",
        "for text in leg.get_texts():\n",
        "    text.set_color('white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results\n",
        "\n",
        "- `one_step_metrics` reports t+1 quality over the test split.\n",
        "- `recursive_close_mae/rmse` report 15-step recursive error accumulation.\n",
        "- The final chart is intentionally grayscale on black, with predicted candles emphasized in white.\n",
        "\n",
        "## Next steps\n",
        "\n",
        "- Increase training coverage with a data provider that guarantees full 60-day 1-minute history.\n",
        "- Add walk-forward evaluation windows.\n",
        "- After baseline lock-in, extend to multi-symbol training and then crypto.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
